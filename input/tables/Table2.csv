Package;Category;Reason to Discard (where);Dep/Func;Algorithm/Type;Additional Comments;
appnn;AP;This package provides a feed forward neural network to predict the amyloidogenicity propensity of polypeptide sequences (DESC);0;??;;
autoencoder;AP;This package provides a sparse autoencoder, an unsupervised algorithm that learns useful features from the data its given (::autoencode);optim();L-BFGS-B, ;well documented, good choice of optim();
BNN;RE*;This package uses a feed forward neural network to perform regression as provided in the examples, however, it is unclear whether it fits the form of perceptron that is the scope of our research. Moreover, it states that it is intended for variable selection. Although how exactly the package would be used to do so isn't accessible in the package, especially considering the source code is based on .c code that users of R might not understand. It's performance is slow, which may have to do with the 100.000 iterations it needs, although quite accurate for simple datasets. (::BNNsel-examples & abstract of paper);/src;??;;
Buddle;RE;;;;;
cld2;00;This package provides bindings to Google's C++ library CLD2, which detects languages using a Naïve Bayesian classifier. CLD3, which does use neural networks, is mentioned in the description (DESC & link to github);X;X;;
cld3;AP;Bindings to Google's C++ library CLD3, which detects languages using a neural network with an experimental algorithm (DESC);/src;??;;
condmixt;AP;This package uses neural networks to predict parameters of mixture models (DESC);-;??;;
DALEX2;;;;;;
DamiaNN;RE? AP?;;;;;
deep;CL;"This package seems to implement a perceptron to classify data (implicitly known from choice of iris as example & in source code: output = function(inputs) {
            as.integer(sum(ws*inputs) - bias > 0)
        },)";-;??;Is it even a neural network? The weights are the same number as they would be for multiple linear regression. Made while author was taking a course;
deepNN;RE;;;;;
DNMF;00;This package helps extract features that enforce spatial locality with separability between classes in a discriminant manner (DESC);X;X;;
evclass;CL;This package provides an evidential neural network that outputs Dempster-Shafer mass functions (DESC);-;??;vignette;
gamlss.add;;;;;;
gcForest;00;"Based on an article with ""Towards an Alternative to Deep Neural Networks"" in it title (DESC)";X;X;vignette;
GMDH;TS;This package provides GMDH type neural network algorithms for short term forecasting on a univariate time series (DESC);-;??;;
GMDH2;CL;This package provides GMDH type neural network algorithms for performing binary classification (DESC);-;??;;
GMDHreg;RE*;"Regression using GMDH algorithms (Title in DESC). We only managed to tested the COMBI algorithm (the most basic and first in the vignette) on the multivariate datasets (it only works for multivariate datasets). It is strangely slow on the ""easy"" datasets, mFriedman and mRef153. The convergence is relatively not good considering the ammount of layers.";-;??;"vignette. One of the references: https://amstat.tandfonline.com/doi/abs/10.1080/00031305.1981.10479358: ""The algorithm, the Group Method of Data Handling (GMDH), builds a multinomial of degree in the hundreds, whereas standard multiple regression becomes bogged down in computation and linear dependence. The GMDH method is ideal for complex, unstructured systems where the investigator is only interested in obtaining a high-order input-output relationship.""";"Jürgen Schmidhuber cites GMDH as one of the first deep learning methods, remarking that it was used to train eight-layer neural nets as early as 1971

From: https://en.wikipedia.org/wiki/Group_method_of_data_handling#cite_note-2 
"
gnn;AP;"""Generative moment matching networks (GMMNs) are introduced for generating quasi-random samples from multivariate models with any underlying copula in order to compute estimates under variance reduction."" (article abstract)";keras::;??;demo. One of the references for the article: http://www.cs.toronto.edu/~zemel/documents/gmmnIcml.pdf ;
grnn;RE;;;;;
hybridEnsemble;RE;Hybrid ensemble of eight different sub-ensembles (DESC);nnet::;BFGS;;
isingLenzMC;AP;"""This package provides utilities to simulate one dimensional Ising Model with Metropolis and Glauber Monte Carlo with single flip dynamics in periodic boundary conditions"" (DESC)";/src;;;
LilRhino;AP;This package provides binary neural networks meant for reducing data (DESC), a random forest style collection of neural networks for classification (::Random_Brains), and code for even more purposes. Documentation is satisfyingly clear for a package for applications: a 3 layer network with an adam optimizer, with an explanation of its activation functions (::Binary_Network). Unfortunately, the packages it chooses for neural networks are not ones we would recommend for regression. However, they may prove to be a good choice for classification in the future (???);keras::;adam;http://wbbpredictions.com/wp-content/uploads/2018/12/Redditbot_Paper.pdf | Uses neuralnet:: for its random brains function.;
learNN;;;;;;
leabRa;;;;;;
kerasformula;;;;;;
kerasR;RE;;;;;
neural;CL;"An implementation of ""a simple MLP neural network that is suitable for classification tasks"" (::mlptrain)";-;back-propagation;GUI?;
NeuralNetTools;UT;"""Functions are available for plotting, quantifying variable importance (Garson's algorithm), conducting a sensitivity analysis (Lek's profile), and obtaining a simple list of model weights"" (DESC - (Help Pages titles))";nnet::;;nnet, RSNNS, neuralnet, caret (2018);
NeuralSens;UT;A greater focus on sensitivity, with additional functions;caret:: & ^;;nnet, RSNNS, neuralnet, caret, h2o, neural (2020);
NlinTS;TS;A non-linear version of a causality test with feed forward neural networks and a Vector Auto-Regressive Neural Network (VARNN) among some other tools for non-linear time series analysis models and causality detection (DESC);/src;stochastic gradient descent (::varmlp);;
nnetpredint;UT;"""Computing prediction intervals of neural network models (e.g.backpropagation) at certain confidence level"" (DESC)";RSNNS::;;nnet, RSNNS, neuralnet (2015);
nnfor;TS;Automatic to fully manual time series modelling with neural networks (DESC);neuralnet::;rprop+;;
nnlib2Rcpp;RE;;;;;
nntrf;AP;Provides useful pre-processing for Machine Learning tasks through data transformation in a non-linear, supervised way with a perceptron (DESC);nnet::;BFGS;vignette, found mlr package ...;
onnx;00'00? UT?;Aims to provide an open source format for neural networks, with definitions of an extensible computation graph model, built-in operators, and standard data types (DESC);X;X;https://onnx.ai/supported-tools.html => doesn't actually seem to include R yet, https://github.com/onnx/models#language, check out the vignette;
OptimClassifier;UT;This package searches for the best amount of neurons for binary classifcation neural networks, among other types of binary classifiers (based on how Optim.NN works & DESC);nnet::;BFGS;Create the Best Train for Classification Models - Title. ML library. vignette. Definition of threshold https://developers.google.com/machine-learning/crash-course/classification/thresholding? Definition of optimization is quite good;"""Optim.NN searches which the number of hidden layers improves the model precision. Then the function searches the best threshold to obtain the best result as possible to your goal"" (vignette)"
OSTSC;UT;A tool to solve imbalanced data for univariate time series classification with oversampling using integrated ESPO and ADASYN methods (DESC) thus improving the performance of RNN classifiers (vignette);suggests keras;examples with adam;vignette - pdf;
passt;AP;This package provides implementation of the Probability Associator Time (PASS-T) model, a memory model based on a simple competitive artificial neural network which imitates human judgment of frequency and duration (DESC);-;??;"vignette. Competitive learning is a form of unsupervised learning in artificial neural networks, in which nodes compete for the right to respond to a subset of the input data. (From: https://en.wikipedia.org/wiki/Competitive_learning#cite_note-1) 
";
pnn;CL;This package provides implementation of the Specht algorithm, 1990, for classification with four functions: learn, smooth, perf, and guess (DESC);-;???;Same author as grnn... so yap & yager vs pnn & grnn + spnn + tsfgrnn;
polyreg;00;polyregression as alternative to NN, removed keyword?;;;;
predictoR;RE;A shiny interface for supervised learning with very minimal documentation. Users may be additionally confused when opening the application only to find that it's default language is Espanol, although this can be changed in the Idioma section. (DESC & ::init_predictor);neuralnet;rprop+;Can algorithm be changed? Good that threshold can be determined;
ProcData;AP;"ProcData provides tools for exploratory process data analysis via functions for ""reading responses from a csv file, process manipulation, action sequence generators, feature extraction methods fitting, and making prediction from sequence models"" (recurrent neural networks). An example dataset is provided. (link + DESC)";/src, keras;??;"Doc structure / examples - ::ProcData. http://www.scientifichpc.com/processdata/procdata.html or the github page could be turned into a vignette, or include into the mentioned help page. ""Process data refers to the data describing participants' problem solving processes in computer-based assessments.""";
QuantumOps;CL?;classifies MNIST, Schuld (2018), removed keyword, in 2019;;;;
quarrint;AP;This package provides two indexes for interaction prediction between groundwater and quarry extension, one of which is an artificial neural network. specified classifier for quarry data. Given the conditions of the area, the neural network gives probabilities for the classes of interaction - low, medium, high, and very high (help page - quarrint-package and DESC);neuralnet;rprop+;"https://ro.uow.edu.au/cgi/viewcontent.cgi?article=7474&context=eispapers (paper), unfortunately no threshold.   ann <- neuralnet(f, data = data[data.train.idx, ],
                   hidden = hidden, rep = rep, ...)";
rasclass;CL;This package provides neural networks as one of the five supervised classification algorithms for raster images with a design meant to facilitate land-cover analysis (DESC);RSNNS::;;"The logit algorithm is imported from the multinom function in the nnet package (::classifyRasclass). 
rasclass-package help page example is cool.";
rcane;RE;This package only provides parameter estimation for linear regression, which was not appropriate for the relationships in our data. (DESC);-;batch GD, stochastic GD, minibatch GD, coordinate descent (DESC);vignette;
regressoR;RE;A manual rich version of predictoR.;neuralnet;rprop+;Even the authors are the same... Is it possible to suggest that they simply combine their packages? There are no dependencies.;
rnn;AP;Implementations of the vanilla Recurrent Neural Network, Long Short-Term Memory (LSTM), and Gated Recurrent Unit (GRU) in native R (DESC);-;backprop? seems to want to add adgrad as well;vignette, but feels more like examples. Some are still empty;
RTextTools;AP;"""A machine learning package for automatic text classification that makes it simple for novice users to get started with machine learning, while allowing experienced users to easily experiment with different settings and algorithm combinations."" (DESC)";/src - for lang, nnet::;BFGS;demos;
ruta;AP;unsupervised neural networks (DESC);;;;
simpleNeural;CL;Neural networks for multi-class or binary classification (DESC);-;backpropagation and gradient descent;Trains a multilayer perceptron with 1 hidden layer and a sigmoid activation function. Don't forget to normalize the data first - sN.normalizeDF(), provided in the package, can be used to do so. (::sN.MLPtrain);
softmaxreg;CL;"""Implementation of 'softmax' regression and classification models with multiple layer neural network"" (DESC)";-;SGD', 'Adagrad', 'RMSprop', 'Moment', 'NAG';Does provide examples;
Sojourn.Data;AP;Stores some neural networks used for Sojourn Accelerometer methods (DESC);caret::, nnet::;BFGS?;"Can't see source code? Ah, works with sojourn. ""An accelerometer is a tool that measures proper acceleration."" (https://en.wikipedia.org/wiki/Accelerometer)
";
spnn;CL;"""Scale invariant version of the original PNN proposed by Specht (1990) with the added functionality of allowing for smoothing along multiple dimensions while accounting for covariances within the data set."" (DESC)";/src, -;???;;
studyStrap;AP;"""Implements multi-study learning algorithms such as merging, the study-specific ensemble (trained-on-observed-studies ensemble) the study strap, the covariate-matched study strap, covariate-profile similarity weighting, and stacking weights with single-study learners from caret."" (DESC)";caret::;;vignette | First, while existing methods weight ensemble elements by cross-study prediction performance, we extend weighting schemes to also incorporate covariate similarity between training data and target validation studies. Second, we introduce a hierarchical resampling scheme to generate pseudo-study replicates (“study straps”) and ensemble classifiers trained on these rather than the original studies themselves. (article: https://www.biorxiv.org/content/10.1101/856385v1);
TeachNet;CL;This package provides neural networks with up to 2 hidden layers, 2 different error functions, and a weight decay for 2 class classification. However it is slow. (DESC & ::TeachNet => more for learning);-;backprop;"""In the beginning the weights are initialized with a standard normal distribution. But this package is due to its very slow code just to understand the backpropagation algorithm. A good package for real training of neural networks is for example 'nnet'."" Like. | Has trace but is not actually that slow...";
tensorflow;RE;;;;;
tfestimators;RE;;;;;
trackdem;AP;An artificial neural network can be trained for filtering false positives present (due to e.g. debris, air bubbles, or reflection) in video materials or image sequences;/src, neuralnet;;vignette;
TrafficBDE;RE*;;;;;
tsfgrnn;TS;"""A general regression neural network (GRNN) is a variant of a Radial Basis Function Network characterized by a fast single-pass learning. 'tsfgrnn' allows you to forecast time series using a GRNN model"" that is autoregressive (DESC) ";-;???;vignette;
yager;RE*;;;???;;
yap;CL;Yet another PNN, with a N-level response, where N > 2 (DESC);-;???;Specht (1990) PNN;
zFactor;AP;Computational algorithms to solve equations and find the 'compressibility' factor `z` of hydrocarbon gases (DESC);-;??;(see also ::z.Ann10, ANN.R);
